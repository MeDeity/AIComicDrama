# AI 漫剧自动化项目梳理

## 一、项目背景与目标

- 目标：只需输入一个故事文本，系统自动完成从文案创作、分镜设计、图片生成、运镜规划到视频合成的全流程，降低视频创作门槛，让个人创作者也能快速产出高质量漫剧视频。
- 特点：
  - 端到端自动化：输入故事 → 输出视频文件；
  - 模块化设计：各环节可单独迭代和替换模型；
  - 可扩展：后续可以接入更多模型、更多风格模板和多语言支持。

## 二、核心用户故事

- 作为创作者，我只想输入一段故事大纲，系统帮我：
  - 补全和润色故事文案；
  - 拆成一幕一幕的分镜和台词；
  - 为每一幕生成合适的画面（人物、场景、风格）；
  - 设计每一幕的运镜（推拉摇移、镜头切换节奏）；
  - 合成配图、字幕、背景音乐和转场，导出完整视频。

初期我们重点支持：
- 单一中文故事输入；
- 横版 16:9 或竖版 9:16 的漫剧视频导出；
- 预定义少量画风模板（例如「二次元」「国漫」「写实漫画」）。

## 三、功能模块拆解

1. 故事输入与管理
   - 接收用户输入的故事文本或大纲；
   - 对故事做基础校验（长度、非法内容过滤等）；
   - 记录创作任务与状态。

2. 文案创作（故事扩写与润色）
   - 对原始故事进行结构化：分章节、分幕、分场景；
   - 对对白、旁白进行润色；
   - 输出结构化的「剧本数据」。

3. 分镜设计
   - 基于剧本数据划分镜头（Shot）；
   - 为每个镜头定义：场景描述、角色、情绪、关键动作；
   - 生成每一镜头对应的图片提示词（prompt）。

4. 图片生成
   - 将镜头的提示词转为可被图像模型使用的 prompt；
   - 调用图片生成服务（本地或云端）；
   - 管理生成多张备选图并选择最优。

5. 运镜规划
   - 根据镜头节奏和情绪，为每段画面设计：
     - 镜头时长；
     - 简单运动轨迹（如从左到右平移、轻微推近、缩放）；
   - 输出用于视频合成的关键帧参数。

6. 视频合成
   - 将图片、字幕（对白和旁白）、运镜参数、BGM、音效组合；
   - 调用视频合成引擎生成最终视频文件；
   - 支持基础导出格式（如 MP4，H.264 编码）。

7. 任务编排与监控
   - 管理从「创建任务 → 各阶段处理 → 完成」的全流程；
   - 支持查询任务进度、重试失败步骤；
   - 记录日志方便后续优化。

## 四、技术选型与总体架构

### 1. 后端框架

- Web API：FastAPI
  - 优点：性能好、异步支持优秀、Pydantic 数据校验强大；
  - 适合搭建清晰的 RESTful API 和后续简单的管理后台接口。

### 2. 模块划分（逻辑层面）

- `api` 层：对外提供 HTTP 接口（提交故事、查询任务、获取结果）。
- `domain` 层：核心业务对象和领域逻辑（故事、剧本、镜头、任务等）。
- `services` 层：具体能力服务，比如文案生成服务、分镜服务、图片生成服务、视频合成服务等。
- `pipeline` 层：工作流和任务编排（串联上述服务，控制执行顺序和状态）。
- `infrastructure` 层：
  - 模型调用封装（例如调用本地/远程大模型、图片模型）；
  - 数据持久化（DB 或轻量文件存储）；
  - 消息队列或任务队列（如果需要异步和并发处理）。

### 3. 典型架构形态

- API 网关（FastAPI 应用）：
  - 接收请求、校验参数、创建创作任务；
  - 将长耗时任务交给后台异步执行。
- 后台任务执行：
  - 初期可用 FastAPI 内部的后台任务（BackgroundTasks）或简单的任务队列；
  - 随项目复杂度增加，可引入 Celery + Redis / RQ 等任务队列系统。
- 模型服务：
  - 文案/对话：大语言模型（可封装为统一接口，支持不同供应商）；
  - 图片：例如 Stable Diffusion / DALL·E 等；
  - 未来可将模型服务拆成独立微服务，当前可以先内嵌调用。
- 存储：
  - 任务与结构化剧本：关系型数据库（PostgreSQL / MySQL）或轻量 SQLite 起步；
  - 图片与视频文件：对象存储（本地磁盘起步，未来可接入云存储）。

## 五、系统流程（从故事到视频）

1. 用户在前端/接口提交故事文本，选择画风和视频参数。
2. FastAPI 接口创建任务，写入数据库，返回任务 ID。
3. 后台任务读取任务：
   - 调用文案服务生成结构化剧本；
   - 调用分镜服务拆分镜头；
   - 为每个镜头生成图片 prompt；
   - 调用图片生成服务，得到每镜头的若干备选图；
   - 选择最终图片，进入运镜规划；
   - 根据剧本时间轴生成每个镜头的运镜参数和字幕时间；
   - 调用视频合成服务，将图片、字幕、运镜和音轨合成视频。
4. 任务状态在每个阶段更新（进行中 / 成功 / 失败），供前端轮询或推送。
5. 完成后提供视频下载链接或播放地址。

## 六、FastAPI 项目结构初步设计

后端代码建议目录结构（后续实现时可按此落地）：

```text
ai_comic_drama/
  app/
    main.py              # 应用入口，创建 FastAPI 实例与路由挂载
    api/
      v1/
        routes_story.py   # 提交故事、查询任务等接口
    core/
      config.py           # 配置管理（环境变量、模型地址等）
      security.py         # 基础安全相关（如简单鉴权，后期再扩展）
    domain/
      models.py           # 领域模型（Story, Script, Scene, Shot, Task 等）
    schemas/
      story.py            # Pydantic 请求/响应模型
      task.py
    services/
      story_writer.py     # 文案创作服务（调用大模型）
      storyboarder.py     # 分镜生成服务
      image_generator.py  # 图片生成服务
      camera_planner.py   # 运镜规划服务
      video_renderer.py   # 视频合成服务
    pipeline/
      workflow.py         # 串联各服务的主工作流
    infrastructure/
      db.py               # 数据库会话与基础 CRUD
      mq.py               # 任务队列/消息队列封装（视情况实现）
      storage.py          # 文件存储（图片/视频）
  tests/
    __init__.py
    test_api_story.py     # 接口与流程相关测试（后续补充）
```

当前阶段，我们先明确结构和职责划分，后续可以按模块逐步实现具体逻辑与模型调用。

## 七、后续迭代规划（简要）

- MVP 版本（当前阶段目标）：
  - 支持文本故事 → 单条视频的端到端流程；
  - 模型可以先用「占位实现」或接入一个基础模型；
  - 优先保证流程打通与任务状态可跟踪。
- 迭代方向：
  - 增加多风格画风和主题模板；
  - 优化分镜和运镜的智能程度；
  - 增加多角色配音和更丰富的音效；
  - 提供可视化创作界面（拖拽式调整分镜等）。

本文件主要聚焦整体梳理和架构设计，后续在 docs 中可以继续拆分出更细的模块设计文档（如「文案模块设计」「分镜与镜头数据结构设计」「视频合成流水线设计」等），便于对外分享和团队协作。

## 附录一：文案创作模块设计（Story Writer）

### 1. 模块目标

- 输入：用户提供的故事大纲或完整故事文本，以及一些控制参数（目标篇幅、风格、受众年龄等）。
- 输出：结构化的剧本数据结构 `Script`：
  - 基本字段示例：`title`、`summary`、`scenes`（场景列表）、`characters`（角色设定）、`beats`（剧情节拍）等；
  - 每个场景包含：场景描述、登场角色、情绪基调、对白与旁白段落。

### 2. 核心职责

- 对原始故事进行理解和拆解（角色、世界观、冲突和主题）。
- 按剧集/幕/场景组织内容，保证故事节奏合理。
- 生成适合漫剧呈现的对白（以镜头为单位的对话块）。
- 为后续分镜和图片生成提供尽量具体且结构化的描述信息。

### 3. 数据结构草案

- `Story`：原始输入
  - `id`
  - `raw_text`：原始故事文本
  - `tone`：基调（轻松、热血、悬疑、恐怖等）
  - `target_length`：目标时长或篇幅
- `Character`：角色信息
  - `name`
  - `role`：主角/配角/反派等
  - `personality`：性格关键词
  - `appearance_hint`：外貌与服饰提示（供后续图片生成用）
- `Scene`：场景
  - `id`
  - `title`
  - `location`：地点描述
  - `time`：时间（白天/夜晚等）
  - `mood`：场景情绪（紧张、温馨等）
  - `description`：整体场景描述
  - `beats`：该场景中的关键剧情节点列表
- `Beat`：剧情节拍
  - `id`
  - `summary`：该节拍发生了什么
  - `dialogues`：对白列表
  - `narration`：旁白
- `Dialogue`：单句对话
  - `speaker`：角色名
  - `text`：对话内容
  - `emotion`：说话时的情绪

这些结构最终可以序列化成 JSON，存入数据库，并作为分镜模块的输入。

### 4. 处理流程

1. 文本预处理
   - 清洗：去除明显的无效内容（例如多余空行、无意义符号）。
   - 识别基础信息：尝试抽取角色名、地点名、关键道具等。
2. 故事结构分析
   - 分章节/幕：根据时间线和冲突发展划分；
   - 识别关键转折点（开端、发展、高潮、结局）。
3. 场景与节拍生成
   - 按照「一个场景解决一个小目标」的思想生成 `Scene` 列表；
   - 为每个 `Scene` 生成若干 `Beat`，每个 `Beat` 对应一小段行动或对话。
4. 对白与旁白创作
   - 为每个 `Beat` 生成对白列表和旁白；
   - 限制每条对白长度，适配屏幕阅读；
   - 使用情绪标签，为后续镜头情绪、BGM 选择提供依据。
5. 输出结构化剧本
   - 将 `Story` + `Characters` + `Scenes` + `Beats` + `Dialogues` 组织成完整 `Script`；
   - 提供给分镜模块作为输入。

### 5. 与模型的交互方式（示意）

- 封装一个统一接口，例如 `StoryWriterService`：
  - 方法：`generate_script(story: Story) -> Script`
  - 内部可能分多次调用大语言模型：
    - 第一次：抽取角色设定和世界观；
    - 第二次：生成场景列表与概要；
    - 第三次：为每个场景生成节拍和对白。
- 交互策略：
  - 为了控制 Token 和成本，可以：
    - 对长故事先做摘要，再分段处理；
    - 分场景逐步生成，而不是一次性生成全本剧本；
  - 对每一步的模型输出进行轻量校验（字段是否齐全、JSON 是否可解析等）。

### 6. 可配置参数示例

- `max_scenes`：最大场景数；
- `max_beats_per_scene`：每个场景最多多少个剧情节拍；
- `dialogue_style`：对白风格（搞笑、日常、严肃等）；
- `age_rating`：受众年龄段（影响内容尺度与语言）。

## 附录二：分镜设计模块设计（Storyboarder）

### 1. 模块目标

- 输入：文案模块输出的 `Script`（包含场景、节拍、对白、旁白、角色与情绪）。
- 输出：镜头列表 `Shot[]`：
  - 每个 `Shot` 包含：镜头类型、构图、场景描述、角色站位、关键动作、情绪、图片生成提示词等。

### 2. 核心职责

- 将抽象的剧本节拍转成可视化镜头序列；
- 决定每句对白/旁白对应多少个镜头以及时间占比；
- 为图片生成模块提供精确且可控的提示词；
- 为运镜模块提供基础的镜头结构（如远景/近景、运动趋势等）。

### 3. 数据结构草案

- `Shot`：
  - `id`
  - `scene_id`
  - `beat_id`
  - `shot_type`：远景/中景/近景/特写等
  - `camera_angle`：平视/俯视/仰视等
  - `composition`：构图（例如三分法、居中等）
  - `characters`：当前镜头中出现的角色及其位置/姿态简述
  - `action`：关键动作描述
  - `emotion`：镜头整体情绪基调
  - `prompt`：图片生成提示词（包含风格、场景、角色、动作、光影等）
  - `negative_prompt`：反向提示词（可选）
- `CharacterInShot`：
  - `name`
  - `position`：大致位置（左/中/右）
  - `pose`：姿态（站立、坐着、奔跑等）
  - `expression`：表情描述

### 4. 设计规则与启发式

- 一般规则：
  - 一句较长对白可以对应一个镜头，也可拆为多个镜头（例如说话前的反应镜头+说话中的近景）；
  - 场景切换时至少使用一个「交代环境」的远景镜头；
  - 情绪激烈时多使用近景/特写；
  - 宁可镜头略少，也要保证观感流畅、节奏清晰。
- 构图与镜头类型选择：
  - 对话场景：多用中景/近景，交替俯视/仰视来表现压迫感或弱势感；
  - 情绪展现：使用特写，突出表情和细节；
  - 行动场景：考虑加入运动方向描述（从左向右奔跑等）为后续运镜做准备。

### 5. 处理流程

1. 场景级规划
   - 遍历 `Script.scenes`，为每个场景先规划：开场镜头（环境）、中段镜头（人物互动）、收束镜头（情绪收尾）。
2. 节拍级拆分
   - 对每个 `Beat`：
     - 判断该节拍是对话型、动作型还是情绪型；
     - 根据类型生成 1~N 个 `Shot`，指定 `shot_type` 与构图。
3. 人物与动作映射
   - 将 `Beat` 中出现的角色映射到 `Shot.characters`；
   - 依据对白内容和情绪为角色分配姿态与表情。
4. 生成图片提示词
   - 综合场景描述、角色外貌、服装、情绪和构图信息；
   - 加入统一的风格控制（如「二次元动漫」「国漫线条」「柔和光影」等），保证整片风格一致；
   - 输出 `prompt` 和可选的 `negative_prompt`。
5. 输出镜头序列
   - 保证镜头序列中 `scene_id`、`beat_id` 与原剧本可追溯；
   - 为运镜模块提供镜头列表与基本参数（例如建议时长、推荐运动趋势）。

### 6. 与其他模块的接口

- 与文案创作模块：
  - 依赖 `Script` 结构字段，尽量避免直接处理原始文本；
  - 如果 `Script` 不完整（缺少角色设定或场景描述），可以约定回退策略（例如用默认模板补全）。
- 与图片生成模块：
  - 主要输出是每个 `Shot` 的 `prompt` 和关键构图信息；
  - 可为同一镜头生成多个候选 prompt，供后续自动或人工选图。
- 与运镜规划模块：
  - 提供镜头类型、预期情绪和镜头之间的关系（是否同一场景、是否对话互切等）；
  - 运镜规划可以在此基础上决定镜头时长和运动轨迹。
